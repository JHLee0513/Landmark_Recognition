{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  https://www.kaggle.com/wolfgangb33r/landmark-recognition-train-a-first-keras-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoonH\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# This first try cannot be run within Kaggle. The kernel expects different image sets within\n",
    "# directories of different classes of landmark ids, e.g.:\n",
    "# /train/2453/images\n",
    "# /train/234/images\n",
    "# /train/3215/images\n",
    "# ...\n",
    "#\n",
    "# Its a typical Keras image classification kernel that is capable of producing propabilities of \n",
    "# classes.\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_DIR = \"./models/\"\n",
    "TRAIN_IMAGE_DIR = \"/Users/JoonH/Desktop/Landmarks_data/train\"\n",
    "VALIDATION_IMAGE_DIR = \"/Users/JoonH/Desktop/Landmarks_data/validation\"\n",
    "img_width, img_height = 128, 128\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_duration (start_time, msg):\n",
    "    print(\"[%d] %s\" % (int(time.time() - start_time), msg))\n",
    "    start_time = time.time()\n",
    "    return start_time\n",
    "\n",
    "\n",
    "def train():\n",
    "\tif os.path.isdir(TRAIN_IMAGE_DIR):\t\n",
    "\n",
    "\t\ttrain_datagen = ImageDataGenerator(\n",
    "\t\t\trescale=1. / 255,\n",
    "    \t\tshear_range=0.2,\n",
    "    \t\tzoom_range=0.2,\n",
    "    \t\thorizontal_flip=True)\n",
    "\n",
    "\t\tval_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\t\ttrain_generator = train_datagen.flow_from_directory(TRAIN_IMAGE_DIR, \n",
    "\t\t\ttarget_size=(img_width, img_height), \n",
    "\t\t\tbatch_size=batch_size,class_mode='categorical')\n",
    "\n",
    "\t\ttotal_val_image_count = train_generator.samples\n",
    "\t\tprint(train_generator.class_indices)\n",
    "\t\tnr_of_classes = len(train_generator.class_indices)\n",
    "\t\tprint(nr_of_classes)\n",
    "\t\t'''\n",
    "\t\t# this is a similar generator, for validation data\n",
    "\t\tvalidation_generator = val_datagen.flow_from_directory(VALIDATION_IMAGE_DIR,\n",
    "        \ttarget_size=(img_width, img_height), \n",
    "        \tbatch_size=batch_size, class_mode='categorical')\n",
    "\t\t'''\n",
    "\t\t\n",
    "\n",
    "\t\tinput_shape = (img_width, img_height, 3)\n",
    "\n",
    "\t\tmodel = Sequential()\n",
    "\t\tmodel.add(Conv2D(120, (3, 3), input_shape=input_shape))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\tmodel.add(Conv2D(80, (3, 3)))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\tmodel.add(Conv2D(80, (3, 3)))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(65))\n",
    "\t\tmodel.add(Activation('relu'))\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\t\tmodel.add(Dense(nr_of_classes))\n",
    "\t\tmodel.add(Activation('sigmoid'))\n",
    "\n",
    "\t\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t              optimizer='sgd',\n",
    "\t\t              metrics=['accuracy'])\n",
    "\n",
    "\t\t\n",
    "\t\t# 'steps_per_epoch: Total number of steps (batches of samples) to yield from generator before declaring one \n",
    "\t\t# epoch finished and starting the next epoch. \n",
    "\t\t# It should typically be equal to the number of unique samples of your dataset divided by the batch size.\n",
    "\t\tmodel.fit_generator(train_generator,epochs=3, steps_per_epoch=1000)\n",
    "\t\tmodel.save(MODEL_DIR + \"model.h5\")\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tprint(\"Training set not found!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e889aa2f7d62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4411d95a87da>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \t\ttrain_generator = train_datagen.flow_from_directory(TRAIN_IMAGE_DIR, \n\u001b[0;32m     19\u001b[0m                         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \t\t\tbatch_size=batch_size,class_mode='categorical')\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mtotal_val_image_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m             interpolation=interpolation)\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m   1184\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
